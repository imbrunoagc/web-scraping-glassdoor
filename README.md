# web-scraper-glassdoor
raspagem dos dados da web-site-glassdoor ( extra칞칚o de empresa/sal치rio por cargo buscado )


## Instala칞칚o

Uso o Python vers칚o 3.10.8

As principais libs que vamos utilizar aqui s칚o:

```bash
requests
```
```bash
bs4 ( BeautifulSoup )
```
```bash
re ( Regex )
```
```bash
pandas
```
```bash
sys
```

## Passo a Passo (Script)

1. Busca de URL (DEF)
2. Busca de pr칩ximas p치ginas da URL requisitada
3. Busca de sal치rios das URLs (DEF)
4. Obten칞칚o dos dados
5. Prepara칞칚o dos dados
6. Escolha de armazenamento dos dados ( .xlsx, .csv e .json ) - N칚o iniciado


## Passo a Passo (Usu치rio)

### 1. P치gina de acesso do Glassdoor (Salary)

<a href="https://ibb.co/DYpR5st"><img src="https://i.ibb.co/XD8CSNb/salary.png" alt="salary" border="0"></a>

> 游녤 ** [Sal치rios](https://www.glassdoor.com.br/Sal%C3%A1rios/index.htm)** 游녣



### 2. Busca de sal치rios por cargo

<a href="https://ibb.co/S0mgjXV"><img src="https://i.ibb.co/ftNWgYr/analista-bi.png" alt="analista-bi" border="0"></a>

> 游녤 ** [al치rios/brasil-analista-bi-sal치rio](https://www.glassdoor.com.br/Sal%C3%A1rios/brasil-analista-bi-sal%C3%A1rio-SRCH_IL.0,6_IN36_KO7,18.htm?clickSource=searchBtn)** 游녣
> 

### 3. Utilizando as fun칞칫es (1.)


```bash
urls = get_urls_glassdoor( "Digite sua URL aqui")
```
```bash
df_salarios = get_salarios_glassdoor(urls)
```

## Apresenta칞칚o dos dados


<a href="https://ibb.co/s66xt0G"><img src="https://i.ibb.co/4YYvJ6G/retorno-analista-bi.png" alt="retorno-analista-bi" border="0"></a>

## Ponto de aten칞칚o

Esse trecho da fun칞칚o `get_urls_glassdoor`, tem um uma linha comentada.
A linha comentada 칠 um for com range de 1 a ultima p치gina do link buscado.

* Comentada para evitar lentid칚o na raspagem dos dados do glassdoor
* Setando o valor do `range( 1, 10)`, para pegar apenas dentro desse intervalo.

```bash
#for i in range(1, int(last_page)): # Next Page do web-site, de forma din칙mica | Comentado: Devido ao alto n칰mero de p치ginas de algumas URLS.
    for i in range(1, 10):
        padrao = r'(\d+)(\.htm)'
        nova_url = re.sub(padrao, rf'\g<1>_IP{i}\2', url).strip()

        urls.append(nova_url)
```


